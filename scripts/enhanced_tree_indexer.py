#!/usr/bin/env python3
"""
Enhanced Simpel trÃ¤dstruktur-indexer fÃ¶r Cold Storage ML-trÃ¤ning
Med progressbar, Ã¥terupptagning och nivÃ¥-fÃ¶r-nivÃ¥ scanning
"""

import os
import json
import argparse
import pickle
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple
import re
import sys
from collections import deque

try:
    from tqdm import tqdm
    HAS_TQDM = True
except ImportError:
    HAS_TQDM = False
    print("âš ï¸ Installera 'tqdm' fÃ¶r progressbar: pip install tqdm")

class EnhancedTreeIndexer:
    def __init__(self):
        self.version = "2.0.0"
        self.checkpoint_file = None
        self.progress_bar = None
        
    def scan_directory_tree(self, root_path: str, output_file: str = None, 
                           include_extensions: List[str] = None,
                           exclude_patterns: List[str] = None,
                           resume: bool = True,
                           checkpoint_interval: int = 1000) -> Dict:
        """
        Scanna katalogtrÃ¤d med progressbar och Ã¥terupptagning
        """
        
        if not os.path.exists(root_path):
            raise FileNotFoundError(f"SÃ¶kvÃ¤g finns inte: {root_path}")
        
        # Setup checkpoint fil
        if output_file:
            self.checkpoint_file = output_file.replace('.json', '_checkpoint.pkl')
        else:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            output_file = f"tree_structure_{timestamp}.json"
            self.checkpoint_file = f"tree_structure_{timestamp}_checkpoint.pkl"
        
        print(f"ğŸ“ Enhanced Tree Indexer v{self.version}")
        print(f"ğŸ“‚ Skannar: {root_path}")
        print(f"ğŸ’¾ Output: {output_file}")
        print(f"ğŸ”„ Checkpoint: {self.checkpoint_file}")
        print(f"â° Starttid: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # Default file extensions
        if include_extensions is None:
            include_extensions = [
                # RAW foto
                '.cr2', '.cr3', '.nef', '.arw', '.dng', '.iiq', '.3fr',
                # Standard foto
                '.jpg', '.jpeg', '.png', '.tiff', '.tif', '.psd',
                # Video
                '.mp4', '.mov', '.avi', '.r3d', '.braw', '.mxf',
                # Audio
                '.wav', '.aiff', '.mp3', '.flac',
                # Dokument
                '.pdf', '.ai', '.eps', '.indd'
            ]
        
        # Default exclude patterns
        if exclude_patterns is None:
            exclude_patterns = [
                r'\.DS_Store$',
                r'Thumbs\.db$', 
                r'\.tmp$',
                r'\.temp$',
                r'/\.',  # Dolda mappar
                r'__MACOSX',
                r'System Volume Information',
                r'\$RECYCLE\.BIN'
            ]
        
        # Kompilera exclude patterns
        exclude_regexes = [re.compile(pattern, re.IGNORECASE) for pattern in exclude_patterns]
        
        # FÃ¶rsÃ¶k Ã¥teruppta frÃ¥n checkpoint
        if resume and os.path.exists(self.checkpoint_file):
            print(f"ğŸ”„ Hittade checkpoint - Ã¥terupptar scanning...")
            try:
                with open(self.checkpoint_file, 'rb') as f:
                    checkpoint_data = pickle.load(f)
                
                tree_data = checkpoint_data['tree_data']
                processed_paths = checkpoint_data['processed_paths']
                start_time = checkpoint_data['start_time']
                
                print(f"ğŸ“Š Ã…terupptar frÃ¥n: {len(processed_paths)} processade sÃ¶kvÃ¤gar")
                print(f"ğŸ“„ Redan: {tree_data['statistics']['total_files']} filer, {tree_data['statistics']['total_directories']} mappar")
                
            except Exception as e:
                print(f"âš ï¸ Kunde inte lÃ¤sa checkpoint: {e}")
                print("ğŸ”„ Startar frÃ¥n bÃ¶rjan...")
                tree_data, processed_paths, start_time = self._initialize_scan_data(
                    root_path, include_extensions, exclude_patterns
                )
        else:
            tree_data, processed_paths, start_time = self._initialize_scan_data(
                root_path, include_extensions, exclude_patterns
            )
        
        # UtfÃ¶r scanning nivÃ¥ fÃ¶r nivÃ¥
        try:
            self._scan_level_by_level(
                root_path, 
                tree_data, 
                processed_paths,
                include_extensions, 
                exclude_regexes,
                checkpoint_interval
            )
            
        except KeyboardInterrupt:
            print(f"\nâš ï¸ Avbrutet av anvÃ¤ndaren - sparar checkpoint...")
            self._save_checkpoint(tree_data, processed_paths, start_time)
            raise
        
        # Slutstatistik
        end_time = datetime.now()
        tree_data['statistics']['scan_duration_seconds'] = (end_time - start_time).total_seconds()
        
        if self.progress_bar:
            self.progress_bar.close()
        
        print(f"\nâœ… Scanning slutfÃ¶rd!")
        print(f"ğŸ“Š Slutstatistik:")
        print(f"   ğŸ“ {tree_data['statistics']['total_directories']} mappar")
        print(f"   ğŸ“„ {tree_data['statistics']['total_files']} filer")
        print(f"   ğŸ“ Djup: {tree_data['statistics']['max_depth']} nivÃ¥er")
        print(f"   â±ï¸  Tid: {tree_data['statistics']['scan_duration_seconds']:.1f} sekunder")
        
        # Visa vanligaste filtyper
        if tree_data['statistics']['file_extensions']:
            print(f"   ğŸ“‹ Top 10 filtyper:")
            sorted_extensions = sorted(
                tree_data['statistics']['file_extensions'].items(), 
                key=lambda x: x[1], 
                reverse=True
            )
            for ext, count in sorted_extensions[:10]:
                print(f"      {ext}: {count:,} filer")
        
        # Spara slutresultat
        self._save_tree_data(tree_data, output_file)
        
        # Rensa checkpoint
        if os.path.exists(self.checkpoint_file):
            os.remove(self.checkpoint_file)
            print(f"ğŸ—‘ï¸ Checkpoint-fil borttagen")
        
        return tree_data
    
    def _initialize_scan_data(self, root_path: str, include_extensions: List[str], 
                             exclude_patterns: List[str]) -> Tuple[Dict, set, datetime]:
        """Initialisera scan-data"""
        
        tree_data = {
            'scan_info': {
                'root_path': root_path,
                'scan_date': datetime.now().isoformat(),
                'scanner': 'EnhancedTreeIndexer',
                'version': self.version,
                'include_extensions': include_extensions,
                'exclude_patterns': exclude_patterns
            },
            'statistics': {
                'total_files': 0,
                'total_directories': 0,
                'file_extensions': {},
                'max_depth': 0,
                'largest_file': {'name': '', 'size': 0},
                'scan_duration_seconds': 0
            },
            'tree': {
                'type': 'directory',
                'name': os.path.basename(root_path) or root_path,
                'path': root_path,
                'children': {},
                'files': [],
                'metadata': {
                    'depth': 0,
                    'file_count': 0,
                    'subdirectory_count': 0
                }
            }
        }
        
        processed_paths = set()
        start_time = datetime.now()
        
        return tree_data, processed_paths, start_time
    
    def _scan_level_by_level(self, root_path: str, tree_data: Dict, processed_paths: set,
                            include_extensions: List[str], exclude_regexes: List,
                            checkpoint_interval: int):
        """
        Scanna katalogtrÃ¤d nivÃ¥ fÃ¶r nivÃ¥ med progressbar
        """
        
        # FÃ¶rsta: rÃ¤kna totalt antal kataloger fÃ¶r progressbar
        print("ğŸ”¢ RÃ¤knar totalt antal kataloger...")
        total_dirs = self._count_total_directories(root_path, exclude_regexes)
        print(f"ğŸ“Š Totalt {total_dirs:,} kataloger att processa")
        
        # Skapa progressbar
        if HAS_TQDM:
            self.progress_bar = tqdm(
                total=total_dirs,
                desc="Scannar kataloger",
                unit="dir",
                bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]"
            )
        
        # KÃ¶ fÃ¶r nivÃ¥-fÃ¶r-nivÃ¥ scanning
        current_level = deque([(root_path, tree_data['tree'], 0)])
        checkpoint_counter = 0
        
        while current_level:
            next_level = deque()
            
            # Processa alla kataloger pÃ¥ nuvarande nivÃ¥
            while current_level:
                dir_path, tree_node, depth = current_level.popleft()
                
                # Hoppa Ã¶ver om redan processad
                if dir_path in processed_paths:
                    if HAS_TQDM and self.progress_bar:
                        self.progress_bar.update(1)
                    continue
                
                # Processa denna katalog
                self._process_directory(
                    dir_path, tree_node, depth, 
                    include_extensions, exclude_regexes,
                    tree_data['statistics'], next_level
                )
                
                processed_paths.add(dir_path)
                checkpoint_counter += 1
                
                # Uppdatera progressbar
                if HAS_TQDM and self.progress_bar:
                    self.progress_bar.set_postfix({
                        'filer': f"{tree_data['statistics']['total_files']:,}",
                        'djup': depth,
                        'ext': len(tree_data['statistics']['file_extensions'])
                    })
                    self.progress_bar.update(1)
                
                # Spara checkpoint
                if checkpoint_counter >= checkpoint_interval:
                    self._save_checkpoint(tree_data, processed_paths, datetime.now())
                    checkpoint_counter = 0
            
            # NÃ¤sta nivÃ¥ blir nuvarande nivÃ¥
            current_level = next_level
    
    def _count_total_directories(self, root_path: str, exclude_regexes: List) -> int:
        """RÃ¤kna totalt antal kataloger (fÃ¶r progressbar)"""
        
        total = 0
        stack = [root_path]
        
        while stack:
            current_path = stack.pop()
            
            # Kontrollera exclude patterns
            if any(regex.search(current_path) for regex in exclude_regexes):
                continue
            
            try:
                items = os.listdir(current_path)
                total += 1
                
                for item in items:
                    item_path = os.path.join(current_path, item)
                    
                    if any(regex.search(item_path) for regex in exclude_regexes):
                        continue
                    
                    if os.path.isdir(item_path):
                        stack.append(item_path)
                        
            except (PermissionError, OSError):
                total += 1  # RÃ¤kna Ã¤ven kataloger vi inte kan lÃ¤sa
                continue
        
        return total
    
    def _process_directory(self, dir_path: str, tree_node: Dict, depth: int,
                          include_extensions: List[str], exclude_regexes: List,
                          statistics: Dict, next_level: deque):
        """
        Processa en enskild katalog
        """
        
        # Uppdatera max djup
        statistics['max_depth'] = max(statistics['max_depth'], depth)
        
        try:
            items = os.listdir(dir_path)
        except PermissionError:
            if not HAS_TQDM:
                print(f"âš ï¸ Ingen Ã¥tkomst till: {dir_path}")
            return
        except Exception as e:
            if not HAS_TQDM:
                print(f"âŒ Fel vid lÃ¤sning av {dir_path}: {e}")
            return
        
        # Sortera items
        items.sort()
        
        for item in items:
            item_path = os.path.join(dir_path, item)
            
            # Kontrollera exclude patterns
            if any(regex.search(item_path) for regex in exclude_regexes):
                continue
            
            if os.path.isdir(item_path):
                # Skapa mapp-nod
                child_node = {
                    'type': 'directory',
                    'name': item,
                    'path': item_path,
                    'children': {},
                    'files': [],
                    'metadata': {
                        'depth': depth + 1,
                        'file_count': 0,
                        'subdirectory_count': 0
                    }
                }
                
                tree_node['children'][item] = child_node
                tree_node['metadata']['subdirectory_count'] += 1
                statistics['total_directories'] += 1
                
                # LÃ¤gg till i nÃ¤sta nivÃ¥
                next_level.append((item_path, child_node, depth + 1))
                
            elif os.path.isfile(item_path):
                # Processa fil
                self._process_file(
                    item, item_path, include_extensions,
                    tree_node, statistics
                )
    
    def _process_file(self, filename: str, file_path: str, 
                     include_extensions: List[str], tree_node: Dict, 
                     statistics: Dict):
        """
        Processa en enskild fil
        """
        
        file_ext = Path(filename).suffix.lower()
        
        # Kontrollera filextension
        if include_extensions and file_ext not in include_extensions:
            return
        
        try:
            file_stat = os.stat(file_path)
            file_size = file_stat.st_size
            
            # Uppdatera statistik
            statistics['total_files'] += 1
            tree_node['metadata']['file_count'] += 1
            
            if file_ext not in statistics['file_extensions']:
                statistics['file_extensions'][file_ext] = 0
            statistics['file_extensions'][file_ext] += 1
            
            if file_size > statistics['largest_file']['size']:
                statistics['largest_file'] = {
                    'name': file_path,
                    'size': file_size
                }
            
            # Fil-info
            file_info = {
                'name': filename,
                'path': file_path,
                'extension': file_ext,
                'size': file_size,
                'modified': datetime.fromtimestamp(file_stat.st_mtime).isoformat(),
                'created': datetime.fromtimestamp(file_stat.st_ctime).isoformat()
            }
            
            tree_node['files'].append(file_info)
            
        except (OSError, IOError) as e:
            if not HAS_TQDM:
                print(f"âš ï¸ Kunde inte lÃ¤sa fil {file_path}: {e}")
    
    def _save_checkpoint(self, tree_data: Dict, processed_paths: set, start_time: datetime):
        """
        Spara checkpoint fÃ¶r Ã¥terupptagning
        """
        
        checkpoint_data = {
            'tree_data': tree_data,
            'processed_paths': processed_paths,
            'start_time': start_time,
            'checkpoint_time': datetime.now().isoformat()
        }
        
        try:
            with open(self.checkpoint_file, 'wb') as f:
                pickle.dump(checkpoint_data, f)
            
            if not HAS_TQDM:
                print(f"ğŸ’¾ Checkpoint sparad: {len(processed_paths)} kataloger, {tree_data['statistics']['total_files']} filer")
                
        except Exception as e:
            if not HAS_TQDM:
                print(f"âš ï¸ Kunde inte spara checkpoint: {e}")
    
    def _save_tree_data(self, tree_data: Dict, output_file: str):
        """
        Spara trÃ¤d-data till fil
        """
        
        print(f"ğŸ’¾ Sparar trÃ¤d-data till: {output_file}")
        
        # Skapa output-katalog om den inte finns
        output_dir = os.path.dirname(output_file)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # Spara som JSON
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(tree_data, f, indent=2, ensure_ascii=False)
        
        file_size = os.path.getsize(output_file)
        print(f"âœ… TrÃ¤d-data sparad ({file_size / 1024:.1f} KB)")
    
    def create_summary_report(self, tree_data: Dict, output_file: str = None):
        """
        Skapa sammanfattningsrapport av trÃ¤d-strukturen
        """
        
        summary = {
            'scan_summary': tree_data['scan_info'],
            'statistics': tree_data['statistics'],
            'structure_analysis': self._analyze_structure(tree_data['tree']),
            'naming_patterns': self._analyze_naming_patterns(tree_data['tree']),
            'recommendations': []
        }
        
        # Generera rekommendationer
        summary['recommendations'] = self._generate_recommendations(summary)
        
        if output_file:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            print(f"ğŸ“Š Sammanfattningsrapport sparad: {output_file}")
        
        return summary
    
    def _analyze_structure(self, tree: Dict) -> Dict:
        """Analysera trÃ¤d-strukturen"""
        
        analysis = {
            'root_directories': list(tree.get('children', {}).keys()),
            'total_depth': self._calculate_max_depth(tree),
            'directory_patterns': {},
            'common_folder_names': {}
        }
        
        # Analysera vanliga mappnamn
        self._collect_folder_names(tree, analysis['common_folder_names'])
        
        # Sortera efter frekvens
        analysis['common_folder_names'] = dict(
            sorted(analysis['common_folder_names'].items(), 
                  key=lambda x: x[1], reverse=True)
        )
        
        return analysis
    

    
    def _analyze_naming_patterns(self, tree: Dict) -> Dict:
        """Analysera namngivningspatterns i filnamn"""
        
        patterns = {
            'date_patterns': {},
            'separator_patterns': {},
            'structure_patterns': {},
            'extension_patterns': {}
        }
        
        def analyze_files_in_node(node):
            for file_info in node.get('files', []):
                filename = file_info['name']
                
                # Analysera datum-patterns
                date_matches = re.findall(r'\d{6}|\d{8}', filename)
                for match in date_matches:
                    pattern_key = f"date_{len(match)}_digits"
                    if pattern_key not in patterns['date_patterns']:
                        patterns['date_patterns'][pattern_key] = 0
                    patterns['date_patterns'][pattern_key] += 1
                
                # Analysera separatorer
                if '_' in filename:
                    patterns['separator_patterns']['underscore'] = patterns['separator_patterns'].get('underscore', 0) + 1
                if '-' in filename:
                    patterns['separator_patterns']['dash'] = patterns['separator_patterns'].get('dash', 0) + 1
                
                # Analysera filextensions
                ext = file_info.get('extension', '')
                if ext:
                    patterns['extension_patterns'][ext] = patterns['extension_patterns'].get(ext, 0) + 1
            
            # Rekursivt genom barn
            for child in node.get('children', {}).values():
                analyze_files_in_node(child)
        
        analyze_files_in_node(tree)
        
        return patterns
    
    def _calculate_max_depth(self, node: Dict, current_depth: int = 0) -> int:
        """BerÃ¤kna maximalt djup i trÃ¤det"""
        
        max_depth = current_depth
        
        for child in node.get('children', {}).values():
            child_depth = self._calculate_max_depth(child, current_depth + 1)
            max_depth = max(max_depth, child_depth)
        
        return max_depth
    
    def _collect_folder_names(self, node: Dict, folder_counts: Dict):
        """Samla alla mappnamn och rÃ¤kna frekvens"""
        
        folder_name = node.get('name', '')
        if folder_name:
            folder_counts[folder_name] = folder_counts.get(folder_name, 0) + 1
        
        for child in node.get('children', {}).values():
            self._collect_folder_names(child, folder_counts)
    
    def _generate_recommendations(self, summary: Dict) -> List[str]:
        """Generera rekommendationer baserat pÃ¥ analys"""
        
        recommendations = []
        
        # Rekommendationer baserat pÃ¥ struktur
        if summary['structure_analysis']['total_depth'] > 6:
            recommendations.append("Mappstrukturen Ã¤r mycket djup (>6 nivÃ¥er) - kan pÃ¥verka prestanda")
        
        # Rekommendationer baserat pÃ¥ namngivning
        naming = summary['naming_patterns']
        if naming['separator_patterns'].get('underscore', 0) > naming['separator_patterns'].get('dash', 0):
            recommendations.append("Underscore (_) Ã¤r vanligaste separatorn - bra fÃ¶r systemkompatibilitet")
        
        # Rekommendationer fÃ¶r filantal
        total_files = summary['statistics']['total_files']
        if total_files > 100000:
            recommendations.append(f"Stort antal filer ({total_files:,}) - Ã¶vervÃ¤g indexering i mindre delar")
        
        return recommendations

def main():
    parser = argparse.ArgumentParser(description='Enhanced TrÃ¤d-indexer med progressbar och Ã¥terupptagning')
    
    parser.add_argument('path', help='SÃ¶kvÃ¤g att scanna')
    parser.add_argument('--output', '-o', help='Output JSON-fil')
    parser.add_argument('--summary', '-s', help='Skapa sammanfattningsrapport')
    parser.add_argument('--extensions', nargs='*', help='Inkludera bara dessa filextensions (t.ex. .jpg .cr3)')
    parser.add_argument('--exclude', nargs='*', help='Exkludera patterns (regex)')
    parser.add_argument('--foto-only', action='store_true', help='Bara foto/video-filer')
    parser.add_argument('--no-resume', action='store_true', help='Starta frÃ¥n bÃ¶rjan (ignorera checkpoint)')
    parser.add_argument('--checkpoint-interval', type=int, default=1000, help='Spara checkpoint var N kataloger (default: 1000)')
    
    args = parser.parse_args()
    
    # Setup output files
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_file = args.output or f"tree_structure_{timestamp}.json"
    
    extensions = None
    if args.foto_only:
        extensions = [
            '.cr2', '.cr3', '.nef', '.arw', '.dng', '.iiq', '.3fr',  # RAW
            '.jpg', '.jpeg', '.png', '.tiff', '.tif', '.psd', '.ai',  # Standard
            '.mp4', '.mov', '.avi', '.r3d', '.braw', '.mxf'  # Video
        ]
    elif args.extensions:
        extensions = [ext if ext.startswith('.') else f'.{ext}' for ext in args.extensions]
    
    exclude_patterns = args.exclude or None
    
    # KÃ¶r enhanced scanning
    indexer = EnhancedTreeIndexer()
    
    try:
        print(f"ğŸš€ Enhanced Tree Indexer - startad")
        if not HAS_TQDM:
            print("ğŸ’¡ Tips: Installera 'tqdm' fÃ¶r visuell progressbar: pip install tqdm")
        
        tree_data = indexer.scan_directory_tree(
            args.path,
            output_file,
            extensions,
            exclude_patterns,
            resume=not args.no_resume,
            checkpoint_interval=args.checkpoint_interval
        )
        
        # Skapa sammanfattning
        summary_file = args.summary or f"tree_summary_{timestamp}.json"
        summary = indexer.create_summary_report(tree_data, summary_file)
        
        print(f"\nğŸ“‹ SLUTRESULTAT:")
        print(f"   ğŸ“ Rot-mappar: {len(summary['structure_analysis']['root_directories'])}")
        print(f"   ğŸ“ Max djup: {summary['structure_analysis']['total_depth']} nivÃ¥er")
        print(f"   ğŸ—‚ï¸ Filtyper: {len(summary['statistics']['file_extensions'])}")
        
        print(f"\nâœ… FÃ¤rdigt! Filer skapade:")
        print(f"   ğŸ“„ TrÃ¤d-struktur: {output_file}")
        print(f"   ğŸ“Š Sammanfattning: {summary_file}")
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸ Scanning avbruten - checkpoint sparad fÃ¶r Ã¥terupptagning")
        print(f"ğŸ’¡ KÃ¶r samma kommando igen fÃ¶r att fortsÃ¤tta")
        return 1
    except Exception as e:
        print(f"âŒ Fel: {e}")
        return 1
    
    return 0

if __name__ == '__main__':
    exit(main())